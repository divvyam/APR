{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46fd49295b665721d524e5d197d6a95c861a04ba"
      },
      "cell_type": "code",
      "source": "import os\nimport csv\nimport pandas as pd\nimport numpy as np\n\nimport datetime\nfrom pandas.io.json import json_normalize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport squarify\n\nfrom sklearn import model_selection, preprocessing, metrics\nplt.style.use('fivethirtyeight')\n\nprint(os.getcwd())\nprint(os.listdir(\"../\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "58882658662cf6ce89fa49b5865c433145b79076"
      },
      "cell_type": "code",
      "source": "def clean_data(df):\n    #since first column contains row number\n#     df.drop([\"Row_num\"], axis=1)\n    #removing  and kesEntityId as simillar fields are already present\n    df = df.drop(columns=[\"Row_num\",\"kesEntityId\"],axis=1)\n    df[\"Popularity\"] = df[\"Popularity\"].apply(pd.to_numeric,downcast='float')\n    df[\"Year\"] = df[\"Year\"].apply(pd.to_numeric,downcast='unsigned')\n    df[\"Month\"] = df[\"Month\"].apply(pd.to_numeric,downcast='unsigned')\n    df = df.dropna(subset=['Venue'])\n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c313ba7bc8ad30eddf94d59dcad39362a348dcc6"
      },
      "cell_type": "code",
      "source": "# df_pub = pd.read_csv(\"../input/scopus-data/ProcessedScopusData.csv\")\n# If this doesn't work, please change it to the path where the file is locaed in your PC\ndf_pub = pd.read_csv(\"Data/ProcessedScopusData.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "279398cf3313d739b569f574e6074e27cefe0240"
      },
      "cell_type": "code",
      "source": "def append_pub_score(df):\n    print(\"Unique Publications from Scopus:\",len(df_pub.Title.unique()))\n    # Analysing Common Publications\n    vfn_list = df.Venue.unique().tolist()\n    scopus_list = df_pub.Title.unique().tolist()\n    count = 0\n    for pub in scopus_list:\n        if pub in vfn_list:\n            count +=1\n    print(\"Publications present in Dataset:\",count)\n    print(\"Shape Before\",df.shape)\n    df = df[df.Venue.isin(scopus_list)]\n    print(\"Shape After\",df.shape)\n    #score appending\n    score_dict = pd.Series(df_pub.SJR.values,index=df_pub.Title).to_dict()\n    df[\"Publication_Rank\"] = df.apply(lambda row: score_dict[row[\"Venue\"]],axis = 1)\n    return df\n\ndef extract_field(row):\n    val = row[\"Domain\"]\n    index = val.rfind(\"FN\")\n    val = val[index+3:len(val)]\n    val = val.strip(\":}] '\")\n    return val\n\ndef get_num_authors(row):\n    vals = row[\"Authors\"].split(\"},\")\n    return len(vals)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53233bed795c7bef73f8954e5125c8982d909c02"
      },
      "cell_type": "code",
      "source": "label_dict = {\"C\":0,\"J\":1,\"CJ\":2,\"O\":3}\ndef find_conference_type(row):\n    if pd.isnull(row[\"Conference\"]) and pd.isnull(row[\"Journal\"]):\n        return label_dict[\"O\"]\n    elif pd.isnull(row[\"Conference\"]):\n        return label_dict[\"J\"]\n    elif pd.isnull(row[\"Journal\"]):\n        return label_dict[\"C\"]\n    else:\n        return label_dict[\"CJ\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "9d57b8da22246e6b63c80f18ce99402a61145f9f"
      },
      "cell_type": "code",
      "source": "def tidy_split(df, column, sep='|', keep=False):\n    indexes = list()\n    id_values = list()\n    name_values = list()\n    df = df.dropna(subset=[column])\n    for i, presplit in enumerate(df[column].astype(str)):\n        values = presplit.split(sep)\n        if keep and len(values) > 1:\n            indexes.append(i)\n            id_values.append(presplit)\n        for value in values:\n            indexes.append(i)\n            val = value\n            index1 = val.find(\"AuId\")\n            index2 = val.find(\"AfN\")\n            index3 = val.find(\"'S'\")\n            if index3 < index1:\n                val = val[index1+4:index2]\n                val = val.strip(\"', :\")\n            else:\n                val = val[index1+4:index3]\n                val = val.strip(\"', :\")                \n            id_values.append(val)\n            index1 = value.find(\"AuN\")\n            val = value[index1+3:]\n            val = val.strip(\"': }]\")\n            name_values.append(val)\n    new_df = df.iloc[indexes, :].copy()\n    new_df[column+\"_Id\"] = id_values\n    new_new_df = new_df.iloc[:, :].copy()\n    new_new_df[column+\"_Name\"] = name_values\n    return new_new_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "160a079098ca48923a3d01d3ab31a48c83a0dc93"
      },
      "cell_type": "code",
      "source": "def process_year(df):\n    # Make more sensible column names\n    rename_dict = {\"AA\": \"Authors\", \n                   \"C\": \"Conference\", \n                   \"CC\": \"Citation_count\",\n                   \"ECC\": \"Expected_count\",\n                   \"D\": \"Date\", \n                   \"F\": \"Domain\", \n                   \"J\": \"Journal\", \n                   \"RId\": \"References\", \n                   \"Ti\": \"Title\", \n                   \"VFN\": \"Venue\", \n                   \"W\": \"Words\", \n                   \"Y\": \"Year\", \n                   \"logprob\":\"Popularity\",\n                   \"Unnamed: 0\": \"Row_num\"}\n    df.rename(index=str, columns=rename_dict, inplace=True)\n    df.drop_duplicates(subset=['Title'], inplace=True)\n    df[\"Month\"] = pd.to_datetime(df[\"Date\"]).dt.month\n    df = clean_data(df)\n    df = append_pub_score(df)\n    df[\"Publication Type\"] = df.apply(lambda row:find_conference_type(row),axis=1)\n    df[\"Number_Of_authors\"] = df.apply(lambda row:get_num_authors(row), axis = 1)\n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84ab90dee99dd6123cf5ac182279833ca1649d8a"
      },
      "cell_type": "code",
      "source": "# df = pd.read_csv(\"../input/mag-2007/mag_2007.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0540769347b899c896f42090084fe66b3bece32d"
      },
      "cell_type": "code",
      "source": "# df = process_year(df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0ff4542f6f1b8442a2462beee3199a36c70b9c7"
      },
      "cell_type": "code",
      "source": "# df.to_csv(\"mag_2007_processed.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d1abd32ba5ad7c8fe3df8a76a33be8a923fafa7"
      },
      "cell_type": "code",
      "source": "print(os.listdir(\"../input/processedmagdata\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0837b685bdba1a91db8c407bdf324dc6ee22f8dc"
      },
      "cell_type": "code",
      "source": "columns = ['Unnamed: 0','Authors', 'Conference','Citation_count','Date','Expected_count','Domain','Id','Journal','References','Title','Venue','Words','Year','Popularity','Month','Publication_Rank','Publication Type','Number_Of_authors']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a0818183568ad420a028de7a70150696174b824"
      },
      "cell_type": "code",
      "source": "df = pd.DataFrame(columns = columns)\n# please give a path that works on your machine. Keep all the processed files in this path\npath = \"../input/processedmagdata\"\nfor file in os.listdir(path):\n#     print(file)\n    df_temp = pd.read_csv(path+\"/\"+file)\n    df = df.append(df_temp)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5e8e78d5647090a2a7a6e9cdfde7ed7dcb4f248"
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9dcd8173b5764ea7bbb93dd64b7166d832b7099a"
      },
      "cell_type": "code",
      "source": "df = df.drop(['Unnamed: 0','kesEntityId'],axis = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "04e04e4b238be5b28e13c5fba39aa8e44df42398"
      },
      "cell_type": "code",
      "source": "df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ced356d7d51e03fc56b07bae2ff12a341f5b91d9"
      },
      "cell_type": "code",
      "source": "df[\"Publication Type\"].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a34194cb5f1bb681c81dd47f427ce214b40c6c80"
      },
      "cell_type": "code",
      "source": "max(df.Number_Of_authors)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c34935fb136d4e423a2fbaa9937a0f2739d1dbe"
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nsns.set(style=\"darkgrid\")\nax = sns.countplot(x=\"Publication Type\", data=df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7cbb405aedcc02fd04376a2bc0019df8e0c21380"
      },
      "cell_type": "code",
      "source": "# import seaborn as sns\n# sns.set(style=\"darkgrid\")\n# ax = sns.countplot(x=\"Venue\", data=df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c66a334f73cd02c8e5dfdc65c71c6612cb447f9"
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nsns.set(style=\"darkgrid\")\nax = sns.countplot(x=\"Year\", data=df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b50960ab2a4dfbff1da597d41543e3b2cc29e8ee"
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nsns.set(style=\"darkgrid\")\nax = sns.countplot(x=\"Month\", data=df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73fb9d4b7df84d0137bb6ef39211284f409e07b0"
      },
      "cell_type": "code",
      "source": "outlink_map = {}\ninlink_map = {}\ndf_new = df[df[\"References\"].notnull()]\nfor index, row in df_new.iterrows():\n    ref = row[\"References\"]\n    ref_list = list(map(int,ref.strip(\"[]'\").split(\",\")))\n    outlink_map[row[\"Id\"]] = ref_list\n    for ref in ref_list:\n        listi = inlink_map.get(ref, [])\n        listi.append(row[\"Id\"])\n        inlink_map[ref] = listi",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11ae31ad9925e4bb1970747e3f495fddc7e79fec"
      },
      "cell_type": "code",
      "source": "def calculate_page_rank():\n    count = 0\n    page_year = {row[\"Id\"]:row[\"Year\"] for _t, row in df.iterrows()}\n    year_citation_count = { page_year[index]:0 for index in page_year}\n    year_paper_count = { page_year[index]:0 for index in page_year}\n    avg_year_citation_count = {}\n    for index in page_year:\n        year = page_year[index]\n        len_outlink = len(outlink_map.get(index, []))\n        if len_outlink > 0:\n            year_citation_count[year] += len_outlink\n            year_paper_count[year] += 1\n    for year in year_citation_count:\n        if year_paper_count[year] > 0:\n            avg_year_citation_count[year] = year_citation_count[year]/year_paper_count[year]\n    page_rank = {}\n    updated_page_rank = {}\n    for index in df[\"Id\"]:\n        page_rank[index] = 1\n    while True:\n        count += 1\n        flag = True\n        for key in page_rank:\n            cs = page_rank[key]\n            if key in inlink_map:\n                inlink_list = inlink_map[key]\n                ns = 0\n                for link in inlink_list:\n                    if link in page_rank and link in outlink_map:\n                        ns += page_rank[link]/len(outlink_map[link])\n                #ns = 0.15 + (0.85 * ns)\n                ns = 0.15 + float(0.85) * (ns/avg_year_citation_count[page_year[key]])\n                if cs != ns:\n                    flag = False\n                updated_page_rank[key] = ns\n        if flag == True:\n            print(count)\n            break\n        page_rank = updated_page_rank\n        updated_page_rank = {}\n        max_score = max(page_rank.values())\n        print(f\"max score is {max_score}\")\n        page_rank = { index:score/max_score for index, score in page_rank.items()}\n        return page_rank",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46652242cea394b2855919dde313a39be7e50ad1"
      },
      "cell_type": "code",
      "source": "page_rank = calculate_page_rank()\nprint(max(page_rank.values()))\nprint(sum(page_rank.values()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f489dcdbb52b1103175e9c9c903f3b4b7d6cbaa"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b19f35a3938a1a9bc87cd28e3839089d0b40db6c"
      },
      "cell_type": "code",
      "source": "df[\"page_rank\"] = 0\ndef update_rank(row):\n    if row[\"Index_Id\"] in page_rank:\n        return page_rank[row[\"Index_Id\"]]\n    else:\n        return 0\ndf[\"page_rank\"] = df.apply(lambda row: update_rank(row),axis = 1)\ndf[\"page_rank\"][0:10]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f49cc35e40b10d52c8b0df5d75d1f2c55f7db3f"
      },
      "cell_type": "code",
      "source": "df.to_csv(\"ranked_processed_data.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e74cfbedd0f25b1c5d34ad32f0fc1531b9df6835"
      },
      "cell_type": "code",
      "source": "# from sklearn.utils.extmath import softmax\n# df[\"page_rank\"]  = softmax(df[\"page_rank\"].values())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78860dfa67476d65df9ac8ed014a7807aff3d74f"
      },
      "cell_type": "code",
      "source": "# df.to_csv(\"ranked_softmax_processed_data.csv\")",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}