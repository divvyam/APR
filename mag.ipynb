{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46fd49295b665721d524e5d197d6a95c861a04ba"
      },
      "cell_type": "code",
      "source": "import os\nimport csv\nimport pandas as pd\nimport numpy as np\n\nimport datetime\nfrom pandas.io.json import json_normalize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport squarify\n\nfrom sklearn import model_selection, preprocessing, metrics\nplt.style.use('fivethirtyeight')\n\nprint(os.getcwd())\nprint(os.listdir(\"../\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "58882658662cf6ce89fa49b5865c433145b79076"
      },
      "cell_type": "code",
      "source": "def clean_data(df):\n    #since first column contains row number\n#     df.drop([\"Row_num\"], axis=1)\n    #removing  and kesEntityId as simillar fields are already present\n    df = df.drop(columns=[\"Row_num\",\"kesEntityId\"],axis=1)\n    df[\"Popularity\"] = df[\"Popularity\"].apply(pd.to_numeric,downcast='float')\n    df[\"Year\"] = df[\"Year\"].apply(pd.to_numeric,downcast='unsigned')\n    df[\"Month\"] = df[\"Month\"].apply(pd.to_numeric,downcast='unsigned')\n    df = df.dropna(subset=['Venue'])\n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c313ba7bc8ad30eddf94d59dcad39362a348dcc6"
      },
      "cell_type": "code",
      "source": "df_pub = pd.read_csv(\"../input/scopus-data/ProcessedScopusData.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "279398cf3313d739b569f574e6074e27cefe0240"
      },
      "cell_type": "code",
      "source": "def append_pub_score(df):\n    print(\"Unique Publications from Scopus:\",len(df_pub.Title.unique()))\n    # Analysing Common Publications\n    vfn_list = df.Venue.unique().tolist()\n    scopus_list = df_pub.Title.unique().tolist()\n    count = 0\n    for pub in scopus_list:\n        if pub in vfn_list:\n            count +=1\n    print(\"Publications present in Dataset:\",count)\n    print(\"Shape Before\",df.shape)\n    df = df[df.Venue.isin(scopus_list)]\n    print(\"Shape After\",df.shape)\n    #score appending\n    score_dict = pd.Series(df_pub.SJR.values,index=df_pub.Title).to_dict()\n    df[\"Publication_Rank\"] = df.apply(lambda row: score_dict[row[\"Venue\"]],axis = 1)\n    return df\n\ndef extract_field(row):\n    val = row[\"Domain\"]\n    index = val.rfind(\"FN\")\n    val = val[index+3:len(val)]\n    val = val.strip(\":}] '\")\n    return val\n\ndef get_num_authors(row):\n    vals = row[\"Authors\"].split(\"},\")\n    return len(vals)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53233bed795c7bef73f8954e5125c8982d909c02"
      },
      "cell_type": "code",
      "source": "label_dict = {\"C\":0,\"J\":1,\"CJ\":2,\"O\":3}\ndef find_conference_type(row):\n    if pd.isnull(row[\"Conference\"]) and pd.isnull(row[\"Journal\"]):\n        return label_dict[\"O\"]\n    elif pd.isnull(row[\"Conference\"]):\n        return label_dict[\"J\"]\n    elif pd.isnull(row[\"Journal\"]):\n        return label_dict[\"C\"]\n    else:\n        return label_dict[\"CJ\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "9d57b8da22246e6b63c80f18ce99402a61145f9f"
      },
      "cell_type": "code",
      "source": "def tidy_split(df, column, sep='|', keep=False):\n    indexes = list()\n    id_values = list()\n    name_values = list()\n    df = df.dropna(subset=[column])\n    for i, presplit in enumerate(df[column].astype(str)):\n        values = presplit.split(sep)\n        if keep and len(values) > 1:\n            indexes.append(i)\n            id_values.append(presplit)\n        for value in values:\n            indexes.append(i)\n            val = value\n            index1 = val.find(\"AuId\")\n            index2 = val.find(\"AfN\")\n            index3 = val.find(\"'S'\")\n            if index3 < index1:\n                val = val[index1+4:index2]\n                val = val.strip(\"', :\")\n            else:\n                val = val[index1+4:index3]\n                val = val.strip(\"', :\")                \n            id_values.append(val)\n            index1 = value.find(\"AuN\")\n            val = value[index1+3:]\n            val = val.strip(\"': }]\")\n            name_values.append(val)\n    new_df = df.iloc[indexes, :].copy()\n    new_df[column+\"_Id\"] = id_values\n    new_new_df = new_df.iloc[:, :].copy()\n    new_new_df[column+\"_Name\"] = name_values\n    return new_new_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "160a079098ca48923a3d01d3ab31a48c83a0dc93"
      },
      "cell_type": "code",
      "source": "def process_year(df):\n    # Make more sensible column names\n    rename_dict = {\"AA\": \"Authors\", \n                   \"C\": \"Conference\", \n                   \"CC\": \"Citation_count\",\n                   \"ECC\": \"Expected_count\",\n                   \"D\": \"Date\", \n                   \"F\": \"Domain\", \n                   \"J\": \"Journal\", \n                   \"RId\": \"References\", \n                   \"Ti\": \"Title\", \n                   \"VFN\": \"Venue\", \n                   \"W\": \"Words\", \n                   \"Y\": \"Year\", \n                   \"logprob\":\"Popularity\",\n                   \"Unnamed: 0\": \"Row_num\"}\n    df.rename(index=str, columns=rename_dict, inplace=True)\n    df.drop_duplicates(subset=['Title'], inplace=True)\n    df[\"Month\"] = pd.to_datetime(df[\"Date\"]).dt.month\n    df = clean_data(df)\n    df = append_pub_score(df)\n    df[\"Publication Type\"] = df.apply(lambda row:find_conference_type(row),axis=1)\n    df[\"Number_Of_authors\"] = df.apply(lambda row:get_num_authors(row), axis = 1)\n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84ab90dee99dd6123cf5ac182279833ca1649d8a"
      },
      "cell_type": "code",
      "source": "df = pd.read_csv(\"../input/mag-2007/mag_2007.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0540769347b899c896f42090084fe66b3bece32d"
      },
      "cell_type": "code",
      "source": "# Preprocessed files are saved in drive, we do not need to process it. Download those files and read them\n# df = process_year(df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0ff4542f6f1b8442a2462beee3199a36c70b9c7"
      },
      "cell_type": "code",
      "source": "# df.to_csv(\"mag_2007_processed.csv\")",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}