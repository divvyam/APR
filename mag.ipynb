{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46fd49295b665721d524e5d197d6a95c861a04ba"
      },
      "cell_type": "code",
      "source": "import os\nimport csv\nimport pandas as pd\nimport numpy as np\n\nimport datetime\nfrom pandas.io.json import json_normalize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport squarify\n\nfrom sklearn import model_selection, preprocessing, metrics\nplt.style.use('fivethirtyeight')\n\nprint(os.getcwd())\nprint(os.listdir(\"../\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "58882658662cf6ce89fa49b5865c433145b79076"
      },
      "cell_type": "code",
      "source": "def clean_data(df):\n    #since first column contains row number\n#     df.drop([\"Row_num\"], axis=1)\n    #removing  and kesEntityId as simillar fields are already present\n    df = df.drop(columns=[\"Row_num\",\"kesEntityId\"],axis=1)\n    df[\"Popularity\"] = df[\"Popularity\"].apply(pd.to_numeric,downcast='float')\n    df[\"Year\"] = df[\"Year\"].apply(pd.to_numeric,downcast='unsigned')\n    df[\"Month\"] = df[\"Month\"].apply(pd.to_numeric,downcast='unsigned')\n    df = df.dropna(subset=['Venue'])\n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c313ba7bc8ad30eddf94d59dcad39362a348dcc6"
      },
      "cell_type": "code",
      "source": "# df_pub = pd.read_csv(\"../input/scopus-data/ProcessedScopusData.csv\")\n# If this doesn't work, please change it to the path where the file is locaed in your PC\n# df_pub = pd.read_csv(\"Data/ProcessedScopusData.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "279398cf3313d739b569f574e6074e27cefe0240"
      },
      "cell_type": "code",
      "source": "def append_pub_score(df):\n    print(\"Unique Publications from Scopus:\",len(df_pub.Title.unique()))\n    # Analysing Common Publications\n    vfn_list = df.Venue.unique().tolist()\n    scopus_list = df_pub.Title.unique().tolist()\n    count = 0\n    for pub in scopus_list:\n        if pub in vfn_list:\n            count +=1\n    print(\"Publications present in Dataset:\",count)\n    print(\"Shape Before\",df.shape)\n    df = df[df.Venue.isin(scopus_list)]\n    print(\"Shape After\",df.shape)\n    #score appending\n    score_dict = pd.Series(df_pub.SJR.values,index=df_pub.Title).to_dict()\n    df[\"Publication_Rank\"] = df.apply(lambda row: score_dict[row[\"Venue\"]],axis = 1)\n    return df\n\ndef extract_field(row):\n    val = str(row[\"Domain\"])\n    index = val.rfind(\"FN\")\n    val = val[index+3:len(val)]\n    val = val.strip(\":}] '\")\n    return val\n\ndef get_num_authors(row):\n    vals = row[\"Authors\"].split(\"},\")\n    return len(vals)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53233bed795c7bef73f8954e5125c8982d909c02"
      },
      "cell_type": "code",
      "source": "label_dict = {\"C\":0,\"J\":1,\"CJ\":2,\"O\":3}\ndef find_conference_type(row):\n    if pd.isnull(row[\"Conference\"]) and pd.isnull(row[\"Journal\"]):\n        return label_dict[\"O\"]\n    elif pd.isnull(row[\"Conference\"]):\n        return label_dict[\"J\"]\n    elif pd.isnull(row[\"Journal\"]):\n        return label_dict[\"C\"]\n    else:\n        return label_dict[\"CJ\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d57b8da22246e6b63c80f18ce99402a61145f9f"
      },
      "cell_type": "code",
      "source": "def tidy_split(df, column, sep='|', keep=False):\n    indexes = list()\n    id_values = list()\n    name_values = list()\n    df = df.dropna(subset=[column])\n    for i, presplit in enumerate(df[column].astype(str)):\n        values = presplit.split(sep)\n        if keep and len(values) > 1:\n            indexes.append(i)\n            id_values.append(presplit)\n        for value in values:\n            indexes.append(i)\n            val = value\n            index1 = val.find(\"AuId\")\n            index2 = val.find(\"AfN\")\n            index3 = val.find(\"'S'\")\n            if index3 < index1:\n                val = val[index1+4:index2]\n                val = val.strip(\"', :\")\n            else:\n                val = val[index1+4:index3]\n                val = val.strip(\"', :\")                \n            id_values.append(val)\n            index1 = value.find(\"AuN\")\n            val = value[index1+3:]\n            val = val.strip(\"': }]\")\n            name_values.append(val)\n    new_df = df.iloc[indexes, :].copy()\n    new_df[column+\"_Id\"] = id_values\n    new_new_df = new_df.iloc[:, :].copy()\n    new_new_df[column+\"_Name\"] = name_values\n    return new_new_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "160a079098ca48923a3d01d3ab31a48c83a0dc93"
      },
      "cell_type": "code",
      "source": "def process_year(df):\n    # Make more sensible column names\n    rename_dict = {\"AA\": \"Authors\", \n                   \"C\": \"Conference\", \n                   \"CC\": \"Citation_count\",\n                   \"ECC\": \"Expected_count\",\n                   \"D\": \"Date\", \n                   \"F\": \"Domain\", \n                   \"J\": \"Journal\", \n                   \"RId\": \"References\", \n                   \"Ti\": \"Title\", \n                   \"VFN\": \"Venue\", \n                   \"W\": \"Words\", \n                   \"Y\": \"Year\", \n                   \"logprob\":\"Popularity\",\n                   \"Unnamed: 0\": \"Row_num\"}\n    df.rename(index=str, columns=rename_dict, inplace=True)\n    df.drop_duplicates(subset=['Title'], inplace=True)\n    df[\"Month\"] = pd.to_datetime(df[\"Date\"]).dt.month\n    df = clean_data(df)\n    df = append_pub_score(df)\n    df[\"Publication Type\"] = df.apply(lambda row:find_conference_type(row),axis=1)\n    df[\"Number_Of_authors\"] = df.apply(lambda row:get_num_authors(row), axis = 1)\n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84ab90dee99dd6123cf5ac182279833ca1649d8a"
      },
      "cell_type": "code",
      "source": "# df = pd.read_csv(\"../input/mag-2007/mag_2007.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0540769347b899c896f42090084fe66b3bece32d"
      },
      "cell_type": "code",
      "source": "# df = process_year(df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0ff4542f6f1b8442a2462beee3199a36c70b9c7"
      },
      "cell_type": "code",
      "source": "# df.to_csv(\"mag_2007_processed.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d1abd32ba5ad7c8fe3df8a76a33be8a923fafa7"
      },
      "cell_type": "code",
      "source": "print(os.listdir(\"../input/processedmagdata\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0837b685bdba1a91db8c407bdf324dc6ee22f8dc"
      },
      "cell_type": "code",
      "source": "columns = ['Unnamed: 0','Authors', 'Conference','Citation_count','Date','Expected_count','Domain','Id','Journal','References','Title','Venue','Words','Year','Popularity','Month','Publication_Rank','Publication Type','Number_Of_authors']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a0818183568ad420a028de7a70150696174b824"
      },
      "cell_type": "code",
      "source": "df = pd.DataFrame(columns = columns)\n# please give a path that works on your machine. Keep all the processed files in this path\npath = \"../input/processedmagdata\"\nfor file in os.listdir(path):\n#     print(file)\n    df_temp = pd.read_csv(path+\"/\"+file)\n    df = df.append(df_temp)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5e8e78d5647090a2a7a6e9cdfde7ed7dcb4f248"
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9dcd8173b5764ea7bbb93dd64b7166d832b7099a"
      },
      "cell_type": "code",
      "source": "df = df.drop(['Unnamed: 0','kesEntityId'],axis = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "04e04e4b238be5b28e13c5fba39aa8e44df42398"
      },
      "cell_type": "code",
      "source": "df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ced356d7d51e03fc56b07bae2ff12a341f5b91d9"
      },
      "cell_type": "code",
      "source": "df[\"Publication Type\"].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a34194cb5f1bb681c81dd47f427ce214b40c6c80"
      },
      "cell_type": "code",
      "source": "max(df.Number_Of_authors)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c34935fb136d4e423a2fbaa9937a0f2739d1dbe"
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nsns.set(style=\"darkgrid\")\nax = sns.countplot(x=\"Publication Type\", data=df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7cbb405aedcc02fd04376a2bc0019df8e0c21380"
      },
      "cell_type": "code",
      "source": "# import seaborn as sns\n# sns.set(style=\"darkgrid\")\n# ax = sns.countplot(x=\"Venue\", data=df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c66a334f73cd02c8e5dfdc65c71c6612cb447f9"
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nsns.set(style=\"darkgrid\")\nax = sns.countplot(x=\"Year\", data=df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b50960ab2a4dfbff1da597d41543e3b2cc29e8ee"
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nsns.set(style=\"darkgrid\")\nax = sns.countplot(x=\"Month\", data=df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a4a125902935bbc4a524205a9f0f314be6e85a8"
      },
      "cell_type": "code",
      "source": "df[\"Topic\"] = df.apply(lambda row: extract_field(row),axis = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e3f1fa126c37bcd19b6c46270c459ccf0b15cca"
      },
      "cell_type": "code",
      "source": "topic_list = df[\"Topic\"].tolist()\ntopic_dict = {}\ni=0\nfor topic in topic_list:\n    topic_dict[topic] = i\n    i += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24d65faf3645a7133f8a6669ea7cd7c86c3a5827"
      },
      "cell_type": "code",
      "source": "len(topic_dict)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "326e4c67c03d11cf92213cfdc4a8df825b8c0b25"
      },
      "cell_type": "code",
      "source": "venue_list = df[\"Venue\"].tolist()\nvenue_dict = {}\ni=0\nfor venue in venue_list:\n    venue_dict[venue] = i\n    i += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16722486ee31e7642efab181e7a2780dce39ca0c"
      },
      "cell_type": "code",
      "source": "# df[\"Topic_Label\"] = df.apply(lambda row: topic_dict[row[\"Topic\"]],axis = 1)\ndf[\"Year Since Publication\"] = df.apply(lambda row: 2018-row[\"Year\"],axis =1)\ndf[\"Venue_label\"] = df.apply(lambda row: venue_dict[row[\"Venue\"]],axis = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0d15944e5723f0939078f41da421f0c07cad856b"
      },
      "cell_type": "code",
      "source": "del venue_list\ndel topic_list",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73fb9d4b7df84d0137bb6ef39211284f409e07b0"
      },
      "cell_type": "code",
      "source": "outlink_map = {}\ninlink_map = {}\ndf_new = df[df[\"References\"].notnull()]\nfor index, row in df_new.iterrows():\n    ref = row[\"References\"]\n    ref_list = list(map(int,ref.strip(\"[]'\").split(\",\")))\n    outlink_map[row[\"Id\"]] = ref_list\n    for ref in ref_list:\n        listi = inlink_map.get(ref, [])\n        listi.append(row[\"Id\"])\n        inlink_map[ref] = listi",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11ae31ad9925e4bb1970747e3f495fddc7e79fec"
      },
      "cell_type": "code",
      "source": "def calculate_page_rank():\n    count = 0\n    page_year = {row[\"Id\"]:row[\"Year\"] for _t, row in df.iterrows()}\n    year_citation_count = { page_year[index]:0 for index in page_year}\n    year_paper_count = { page_year[index]:0 for index in page_year}\n    avg_year_citation_count = {}\n    for index in page_year:\n        year = page_year[index]\n        len_outlink = len(outlink_map.get(index, []))\n        if len_outlink > 0:\n            year_citation_count[year] += len_outlink\n            year_paper_count[year] += 1\n    for year in year_citation_count:\n        if year_paper_count[year] > 0:\n            avg_year_citation_count[year] = year_citation_count[year]/year_paper_count[year]\n    page_rank = {}\n    updated_page_rank = {}\n    for index in df[\"Id\"]:\n        page_rank[index] = 1\n    while True:\n        count += 1\n        flag = True\n        for key in page_rank:\n            cs = page_rank[key]\n            if key in inlink_map:\n                inlink_list = inlink_map[key]\n                ns = 0\n                for link in inlink_list:\n                    if link in page_rank and link in outlink_map:\n                        ns += page_rank[link]/len(outlink_map[link])\n                #ns = 0.15 + (0.85 * ns)\n                ns = 0.15 + float(0.85) * (ns/avg_year_citation_count[page_year[key]])\n                if cs != ns:\n                    flag = False\n                updated_page_rank[key] = ns\n        if flag == True:\n            print(count)\n            break\n        page_rank = updated_page_rank\n        updated_page_rank = {}\n        max_score = max(page_rank.values())\n        print(f\"max score is {max_score}\")\n        page_rank = { index:score/max_score for index, score in page_rank.items()}\n        return page_rank",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46652242cea394b2855919dde313a39be7e50ad1"
      },
      "cell_type": "code",
      "source": "page_rank = calculate_page_rank()\nprint(max(page_rank.values()))\nprint(sum(page_rank.values()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b19f35a3938a1a9bc87cd28e3839089d0b40db6c"
      },
      "cell_type": "code",
      "source": "df[\"page_rank\"] = 0\ndef update_rank(row):\n    if row[\"Index_Id\"] in page_rank:\n        return page_rank[row[\"Index_Id\"]]\n    else:\n        return 0\ndf[\"page_rank\"] = df.apply(lambda row: update_rank(row),axis = 1)\ndf[\"page_rank\"][0:10]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f49cc35e40b10d52c8b0df5d75d1f2c55f7db3f"
      },
      "cell_type": "code",
      "source": "df.to_csv(\"ranked_processed_data.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "294479b5e0257689e580f3af6fd4e48aa6651f5a"
      },
      "cell_type": "code",
      "source": "df = tidy_split(df,\"Authors\",\"},\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60b24a5ab8f81c3b62d56cc705a3c5de6bbf386a"
      },
      "cell_type": "code",
      "source": "features = ['Authors_Id','Citation_count','Id','Year','Popularity','Month','Publication_Rank','Publication Type','Number_Of_authors','Topic_Label','Year Since Publication','Venue']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f44afb7776b60cd85b0635ed6dd04ff9b03714a"
      },
      "cell_type": "code",
      "source": "df_train = df[df[\"Year\"] <= 2010]\ndf_dev = df[df[\"Year\"] == 2011]\ndf_eval = df[df[\"Year\"] >= 2011]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "573245d1a73e436e3d633e545f8b48cdeb179de8"
      },
      "cell_type": "code",
      "source": "import lightgbm as lgb \n\nlgb_params = {\"objective\" : \"regression\", \"metric\" : \"rmse\",\n              \"num_leaves\" : 70, \"learning_rate\" : 0.01, \n              \"bagging_fraction\" : 0.75, \"feature_fraction\" : 0.8, \"bagging_frequency\" : 9}\n    \nlgb_train = lgb.Dataset(lgb_train_x, label=lgb_train_y)\nlgb_val = lgb.Dataset(lgb_valid_x, label=lgb_valid_y)\nmodel = lgb.LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=-1, \nlearning_rate=0.01, \nn_estimators=1000, \nmax_bin=255, \nsubsample_for_bin=50000, \nobjective=None, \nmin_split_gain=0, \nmin_child_weight=3,\nmin_child_samples=10, \nsubsample=1, \nsubsample_freq=1, \ncolsample_bytree=1, \nreg_alpha=0.1, \nreg_lambda=0, \nseed=17,\nsilent=False, \nnthread=-1)\nmodel.fit(df_train[features], df_train[\"page_rank\"], eval_set=[(df_dev[features], df_test[\"page_rank\"])])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e7df1f97eeb3bcd56bcfbd8d3757964a4cab9db2"
      },
      "cell_type": "code",
      "source": "pred_dev = model.predict(df_test[features])\npred_test = model.predict(df_test[features])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fc21e8b6cacfe69c5aa877dc310dea78d96b8494"
      },
      "cell_type": "code",
      "source": "df[\"pred_rank\"] = pred_test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "017cc2f310ebc4aedbb2a21f43aebb5992409d1a"
      },
      "cell_type": "code",
      "source": "import math\n\ndef sigmoid(x):\n  return 1 / (1 + math.exp(-x))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01a2ab6a22cfd84a02dafbf8ecf219d73401cf01"
      },
      "cell_type": "code",
      "source": "df_eval['prob'] = df_eval.apply (lambda row: sigmoid(row[\"pred_rank\"]),axis=1)\ndf_eval = df_eval.sort_values(by=['prob'],ascending=False)\nprint(df_eval[0:100])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34314b3c6c3dc0b4fa70388902368bb441bb85eb"
      },
      "cell_type": "code",
      "source": "imp_list = model.feature_importances_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d956fa128f4f1db8b36923fdd1e44004a22bfd98"
      },
      "cell_type": "code",
      "source": "num = sum(imp_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16cc050c8692dc67d1403c264fe926b90e42ff4e"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# sorted(zip(clf.feature_importances_, X.columns), reverse=True)\nfeature_imp = pd.DataFrame(sorted(zip(model.feature_importances_,train_x.columns)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances-01.png')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}